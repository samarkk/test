my_conn_options = {  
    "url": "jdbc:redshift://redshift-cluster-1.cun6wpx0iczb.us-east-1.redshift.amazonaws.com:5439/dev",
    "dbtable": "public.users",
    "user": "awsuser",
    "password": "Admin98919",
    "redshiftTmpDir": 's3a://red-staging-samar',
    "aws_iam_role": "arn:aws:iam::644466320815:role/service-role/AmazonRedshift-CommandsAccessRole-20230127T130200"
}

users_df = spark.read \
    .format("io.github.spark_redshift_community.spark.redshift") \
    .option("url", my_conn_options['url']) \
    .option("dbtable", my_conn_options['dbtable']) \
    .option("tempdir", my_conn_options['redshiftTmpDir']) \
    .option("aws_iam_role", my_conn_options['aws_iam_role']) \
    .option('user', my_conn_options['user']) \
    .option('password', my_conn_options['password']) \
    .load()

users_df.show()

users_df.write \
    .format("io.github.spark_redshift_community.spark.redshift") \
    .option("url", my_conn_options['url']) \
    .option("dbtable", 'userscopy') \
    .option("tempdir", my_conn_options['redshiftTmpDir']) \
    .option("aws_iam_role", my_conn_options['aws_iam_role']) \
    .option('user', my_conn_options['user']) \
    .option('password', my_conn_options['password']) \
    .save()

