https://cvmskk.s3.amazonaws.com/centosbd_aug_2_2023_2.box
ls -l /home/vagrant/hadoopdata
hostname
cat /home/vagrant/hadoop/etc/hadoop/core-site.xml
cat /home/vagrant/hadoop/etc/hadoop/hdfs-site.xml
hdfs namenode -format
tree /home/vagrant/hadoopdata
cp /home/vagrant/hadoop/etc/hadoop/hadoop-env.sh /vagrant
cp /vagrant/hadoop-env.sh /home/vagrant/hadoop/etc/hadoop
https://github.com/samarkk/spark_python
# look for ntbks in this repo - right now, check out spark_transformations, spark_actions

def parseLogs():
    """ Read and parse log file """
    parsed_logs = (sc
                   .textFile(fileLoc)
                   .map(parseApacheLogLine)
                   .cache())
    access_logs = (parsed_logs
                   .filter(lambda s: s[1] == 1)
                   .map(lambda s: s[0])
                   .cache())
    failed_logs = (parsed_logs
                   .filter(lambda s: s[1] == 0)
                   .map(lambda s: s[0]))
    failed_logs_count = failed_logs.count()
    if failed_logs_count > 0:
        print('Number of invalid logline: %d' % failed_logs.count())
        for line in failed_logs.take(20):
            print('Invalid logline: %s' % line)
    print('Read %d lines, successfully parsed %d lines, failed to parse %d lines' % 
          (parsed_logs.count(), access_logs.count(), failed_logs.count()))
    return parsed_logs, access_logs, failed_logs


parsed_logs, access_logs, failed_logs = parseLogs()


